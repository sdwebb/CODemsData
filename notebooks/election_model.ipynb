{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Election NN Model\n",
    "\n",
    "Using the cleaned registration and election result data, built a neural network model for predicting outcomes of elections. Input features are:\n",
    "\n",
    "* Partisan registration in upcoming election\n",
    "* Partisan registration in prior election\n",
    "* Outcome of prior election\n",
    "\n",
    "One of the challenges with predicting election outcomes in Colorado is the variability due to about a third of the state being unaffiliated with the two major parties. The behavior of those unaffiliateds with vary by district, so we need a model that can account for that.\n",
    "\n",
    "We have a pretty limited dataset, using the following combinations\n",
    "\n",
    "| Inputs | Output |\n",
    "|---------|----------|\n",
    "|2012 reg., results, 2016 reg. | 2016 results |\n",
    "|2014 reg., results, 2018 reg. | 2018 results |\n",
    "|2016 reg., results, 2020 reg. | 2020 results |\n",
    "\n",
    "with the final goal of using the 2016 reg. and results + the most current 2020 reg. to predict the 2020 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful imports\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "res_dir = '../data/results/cleaned'\n",
    "reg_dir = '../data/registration/cleaned'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Need to arrange the cleaned CSV files into the inputs and outputs with appropriate groupings.\n",
    "\n",
    "Senate elections are every four years, so prior results from 2012 will be paired with registration in 2016 to predict the 2016 outcome. Similarly with 2014 and 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define some helper functions that will pre-process the data from the cleaned registration and results files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_registration(year):\n",
    "    \"\"\"Given an input year, snag the registration data for that year and collapse the affiliation of active\n",
    "    voters into REP, DEM, OTHER\n",
    "    \n",
    "    Returns a dataframe with columns DISTRICT-COUNTY, REP, DEM, OTHERS\"\"\"\n",
    "    \n",
    "    # read in the data\n",
    "    reg_df = pd.read_csv(reg_dir+'/{}.csv'.format(year))\n",
    "    \n",
    "    # filter out where the county value is empty, which is a \"total\" row\n",
    "    reg_df = reg_df[reg_df['COUNTY'].notnull()]\n",
    "    \n",
    "    # isolate only active voters\n",
    "    active_cols = [col for col in reg_df.columns if '-ACTIVE' in col]\n",
    "    \n",
    "    # find third-party/unaffiliated voter data\n",
    "    other_cols = [col for col in active_cols if 'DEM' not in col and 'REP' not in col]\n",
    "    \n",
    "    # combine all unaffiliateds into one column\n",
    "    reg_df['OTHER-ACTIVE'] = reg_df[other_cols].sum(axis=1)\n",
    "    \n",
    "    # combine the district and county labels into one\n",
    "    reg_df['DIST_COUNTY'] = reg_df['DISTRICT'].astype(str) +'-'+ reg_df['COUNTY'].astype(str)\n",
    "\n",
    "    # pick off only the interesting data\n",
    "    relabel_dict = {\n",
    "        'REP-ACTIVE' : 'REP',\n",
    "        'DEM-ACTIVE' : 'DEM',\n",
    "        'OTHER-ACTIVE' : 'OTHER'\n",
    "    }\n",
    "    new_df = reg_df[['DIST_COUNTY', 'REP-ACTIVE', 'DEM-ACTIVE', 'OTHER-ACTIVE']].rename(columns=relabel_dict)\n",
    "    \n",
    "    return new_df\n",
    "    \n",
    "def get_results(year):\n",
    "    \"\"\"Given an input year, snag the results data for that year and collapse the affiliation of active\n",
    "    candidates into REP, DEM, OTHER\n",
    "    \n",
    "    Returns a dataframe with columns DISTRICT-COUNTY, REP, DEM, OTHERS\"\"\"\n",
    "\n",
    "    # read in the results file\n",
    "    df = pd.read_csv(res_dir+'/{}.csv'.format(year))\n",
    "    \n",
    "    # create a DIST-COUNTY label\n",
    "    df['DIST_COUNTY'] = df['DISTRICT'].astype(str) + '-' + df['COUNTY'].astype(str)\n",
    "    \n",
    "    # isolate third party candidates\n",
    "    parties = ['DEMOCRATIC PARTY', 'REPUBLICAN PARTY']\n",
    "    df['PARTY'][~df['PARTY'].isin(parties)] = 'OTHER'\n",
    "    df['PARTY'][df['PARTY'] == 'REPUBLICAN PARTY'] = 'REP'\n",
    "    df['PARTY'][df['PARTY'] == 'DEMOCRATIC PARTY'] = 'DEM'\n",
    "\n",
    "    # sum over precincts, if precincts exist\n",
    "    agg_cols = {'YES VOTES' : 'sum'}\n",
    "    df = df.groupby([df['DIST_COUNTY'], df['PARTY']], as_index=False).aggregate(agg_cols)\n",
    "    \n",
    "    # Make party votes into columns for each DIST_COUNTY\n",
    "    df = df.pivot(index='DIST_COUNTY', columns='PARTY', values='YES VOTES').fillna(0)\n",
    "    df.reset_index(level=0, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTY       DIST_COUNTY      DEM    OTHER      REP\n",
      "0         SD 10-EL PASO      0.0  15976.0  44200.0\n",
      "1         SD 12-EL PASO      0.0  16365.0  34673.0\n",
      "2         SD 14-LARIMER  46673.0   4994.0  28874.0\n",
      "3         SD 17-BOULDER  45426.0   3848.0  23983.0\n",
      "4         SD 18-BOULDER  66619.0      0.0  18427.0\n",
      "5       SD 19-JEFFERSON  35664.0   5104.0  35080.0\n",
      "6           SD 21-ADAMS  30308.0      0.0  16373.0\n",
      "7       SD 22-JEFFERSON  38845.0      0.0  35008.0\n",
      "8      SD 23-BROOMFIELD  15898.0      0.0  14755.0\n",
      "9         SD 23-LARIMER   2996.0      0.0   5407.0\n",
      "10           SD 23-WELD  15358.0      0.0  23787.0\n",
      "11          SD 25-ADAMS  27961.0   2461.0  20310.0\n",
      "12       SD 26-ARAPAHOE  38744.0      0.0  32890.0\n",
      "13       SD 27-ARAPAHOE  34957.0      0.0  42411.0\n",
      "14       SD 28-ARAPAHOE  37181.0   2459.0  24475.0\n",
      "15       SD 29-ARAPAHOE  30149.0   2420.0  18745.0\n",
      "16       SD 31-ARAPAHOE   1839.0      0.0   1039.0\n",
      "17         SD 31-DENVER  52551.0      0.0  22386.0\n",
      "18         SD 32-DENVER  47995.0      0.0  20505.0\n",
      "19         SD 33-DENVER  51357.0   2579.0   8456.0\n",
      "20        SD 35-ALAMOSA   3508.0    249.0   2837.0\n",
      "21           SD 35-BACA    644.0     81.0   1280.0\n",
      "22           SD 35-BENT    844.0     81.0    958.0\n",
      "23        SD 35-CONEJOS   2129.0    100.0   1828.0\n",
      "24       SD 35-COSTILLA   1147.0    116.0    542.0\n",
      "25        SD 35-CROWLEY    542.0     80.0    850.0\n",
      "26         SD 35-CUSTER    871.0    108.0   1663.0\n",
      "27       SD 35-HUERFANO   2049.0    111.0   1427.0\n",
      "28          SD 35-KIOWA    201.0     25.0    551.0\n",
      "29     SD 35-LAS ANIMAS   3694.0    287.0   2745.0\n",
      "30        SD 35-MINERAL    286.0     18.0    312.0\n",
      "31          SD 35-OTERO   3790.0    268.0   3958.0\n",
      "32        SD 35-PROWERS   1622.0    192.0   2889.0\n",
      "33         SD 35-PUEBLO   4206.0    418.0   5370.0\n",
      "34     SD 35-RIO GRANDE   2310.0    183.0   2944.0\n",
      "35       SD 35-SAGUACHE   1775.0    144.0    963.0\n",
      "36         SD 4-DOUGLAS  24968.0   3437.0  50173.0\n",
      "37        SD 8-GARFIELD  10132.0   1032.0  11745.0\n",
      "38           SD 8-GRAND   3225.0    356.0   4224.0\n",
      "39         SD 8-JACKSON    180.0     25.0    597.0\n",
      "40          SD 8-MOFFAT   1219.0    293.0   4397.0\n",
      "41      SD 8-RIO BLANCO    538.0    133.0   2534.0\n",
      "42           SD 8-ROUTT   6505.0    537.0   5420.0\n",
      "43          SD 8-SUMMIT   7889.0    703.0   5270.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "res_2012 = get_results(2012)\n",
    "print(res_2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it is helpful to combine the all the relevant input and output data for each dist-county into a single input and output dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_regs - [109270.  31106.  10354.    982.   7374.   3811.  16698.  19852.  92607.\n",
      "  82648. 105654.  97144. 105368.  97382.  70892.  42592.  13652.  59092.\n",
      "  75144.  95261.  98298.  88563.  74861.   4355. 100646.  95069.   8382.\n",
      "   2525.   2418.   4843.   2434.   1870.   3467.   4422.    936.   8376.\n",
      "    735.  10492.   6152.  12402.   6682.   3608.]\n",
      "reg_frac_curr = [0.33337604 0.41583617 0.36073015 0.19246436 0.30987253 0.21044345\n",
      " 0.41448078 0.45884546 0.36419493 0.36921644 0.41439037 0.38757926\n",
      " 0.36121023 0.390298   0.3838656  0.39965252 0.35855552 0.37856224\n",
      " 0.38410252 0.36987854 0.3497121  0.37552928 0.36871001 0.38576349\n",
      " 0.35486756 0.33986894 0.31663088 0.24792079 0.29197684 0.15610159\n",
      " 0.20090386 0.2540107  0.23247765 0.26775215 0.24358974 0.26611748\n",
      " 0.19455782 0.30632863 0.30656697 0.30761168 0.26264591 0.30986696]\n",
      "(42, 9)\n",
      "(42, 9)\n",
      "(42, 3)\n",
      "(42, 3)\n",
      "tot_regs - [  1234.  18748.   4353.   2748.  11172.  15009.   2673.   1556.   3037.\n",
      "  22915.   5448.   6958.  29461.  26940.  12796.  17126.  86912.  13293.\n",
      "  19918.  30564.  11213.    689.   4270.  12539.   9063.   1493.  36777.\n",
      "  16503.  25393.   3877.    586.   5329.  93250. 116178.  73029.  81629.\n",
      " 109181.   9620.  17805.   4417.  75340. 116655.  97924.  94103. 106765.\n",
      "  98817.  94874.]\n",
      "reg_frac_curr = [0.2439222  0.34206315 0.30484723 0.25545852 0.32662012 0.37930575\n",
      " 0.28395062 0.27313625 0.2081001  0.37477635 0.31938326 0.42526588\n",
      " 0.40443298 0.3749072  0.4127071  0.36307369 0.34442885 0.40337019\n",
      " 0.36484587 0.46636566 0.44091679 0.29898403 0.40093677 0.46718239\n",
      " 0.34083637 0.33221701 0.39717758 0.34787614 0.35978419 0.39566675\n",
      " 0.5221843  0.38562582 0.39330831 0.36296029 0.43948295 0.41034436\n",
      " 0.4105751  0.43638254 0.39634934 0.45596559 0.41939209 0.4140414\n",
      " 0.41125771 0.42033729 0.37856039 0.40057885 0.40913211]\n",
      "(47, 9)\n",
      "(89, 9)\n",
      "(64, 3)\n",
      "(106, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Will store the district-county data using the standard key format \n",
    "# 'SD [NUMBER]-[COUNTY]' for the Year of the Predicted Results\n",
    "year_pairs = [['2012', '2016'], ['2014', '2018']]\n",
    "\n",
    "X_set = np.array([], dtype=np.float64).reshape(0,9)\n",
    "Y_set = np.array([], dtype=np.float64).reshape(0,3)\n",
    "\n",
    "for pair in year_pairs:\n",
    "    \n",
    "    # The output variables\n",
    "    current_result = get_results(pair[1])\n",
    "    elections = current_result.DIST_COUNTY.unique()\n",
    "    \n",
    "    # The input variables\n",
    "    current_reg = get_registration(pair[1])\n",
    "    current_reg = current_reg[current_reg['DIST_COUNTY'].isin(elections)]\n",
    "    \n",
    "    past_reg = get_registration(pair[0])\n",
    "    past_reg = past_reg[past_reg['DIST_COUNTY'].isin(elections)]\n",
    "    \n",
    "    past_result = get_results(pair[0])\n",
    "    past_result = past_result[past_result['DIST_COUNTY'].isin(elections)]\n",
    "        \n",
    "    tot_regs = current_reg.sum(axis=1).values\n",
    "        \n",
    "    print('tot_regs - {}'.format(tot_regs))\n",
    "\n",
    "    dem_regs = current_reg.DEM.values\n",
    "    rep_regs = current_reg.REP.values\n",
    "    other_regs = current_reg.OTHER.values\n",
    "\n",
    "    reg_frac_curr_d = dem_regs/tot_regs\n",
    "    reg_frac_curr_r = rep_regs/tot_regs\n",
    "    reg_frac_curr_o = other_regs/tot_regs\n",
    "    \n",
    "    print('reg_frac_curr = {}'.format(reg_frac_curr_o))\n",
    "\n",
    "    tot_regs = past_reg.sum(axis=1).values\n",
    "    dem_regs = past_reg.DEM.values\n",
    "    rep_regs = past_reg.REP.values\n",
    "    other_regs = past_reg.OTHER.values\n",
    "\n",
    "    reg_frac_past_d = dem_regs/tot_regs\n",
    "    reg_frac_past_r = rep_regs/tot_regs\n",
    "    reg_frac_past_o = other_regs/tot_regs\n",
    "\n",
    "    dem_votes = past_result.DEM.values\n",
    "    rep_votes = past_result.REP.values\n",
    "    other_votes = past_result.OTHER.values\n",
    "    tot_votes = dem_votes + rep_votes + other_votes\n",
    "\n",
    "    votes_frac_past_d = dem_votes/tot_votes\n",
    "    votes_frac_past_r = rep_votes/tot_votes\n",
    "    votes_frac_past_o = other_votes/tot_votes\n",
    "    \n",
    "    X = np.array([reg_frac_curr_d, reg_frac_curr_r, reg_frac_curr_o,\n",
    "               reg_frac_past_d, reg_frac_past_r, reg_frac_past_o,\n",
    "               votes_frac_past_d, votes_frac_past_r, votes_frac_past_o]).T\n",
    "    \n",
    "    # Now for the outputs\n",
    "    dem_votes = current_result.DEM.values\n",
    "    rep_votes = current_result.REP.values\n",
    "    other_votes = current_result.OTHER.values\n",
    "    tot_votes = dem_votes + rep_votes + other_votes\n",
    "    \n",
    "    votes_frac_curr_d = dem_votes/tot_votes\n",
    "    votes_frac_curr_r = rep_votes/tot_votes\n",
    "    votes_frac_curr_o = other_votes/tot_votes\n",
    "    \n",
    "    Y = np.array([votes_frac_curr_d, votes_frac_curr_r, votes_frac_curr_o]).T\n",
    "    \n",
    "    print(np.shape(X))\n",
    "    X_set = np.vstack([X_set, X])\n",
    "    print(np.shape(X_set))\n",
    "\n",
    "    Y_set = np.vstack([Y_set, Y])\n",
    "    print(np.shape(Y))\n",
    "    print(np.shape(Y_set))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2020 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
